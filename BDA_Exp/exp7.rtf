{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.14393}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 In [1]: from pyspark import SparkConf,SparkContext\par
In [2]: from pyspark.sql import SQLContext,Row\par
In [3]: sc\par
Out[3]: <pyspark.context.SparkContext at 0x7f3953df9d50>\par
In [5]: sqlc = SQLContext(sc)\par
In [6]: twt1=sqlc.jsonFile('file:/home/training/training_materials/data/chatlogs/2014-01-01.json')\par
19/10/12 04:26:06 INFO storage.MemoryStore: ensureFreeSpace(280171) called with curMem=0, maxMem=280248975\par
19/10/12 04:26:06 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 273.6 KB, free 267.0 MB)\par
19/10/12 04:26:06 INFO storage.MemoryStore: ensureFreeSpace(21204) called with curMem=280171, maxMem=280248975\par
19/10/12 04:26:06 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 267.0 MB)\par
19/10/12 04:26:06 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59820 (size: 20.7 KB, free: 267.2 MB)\par
19/10/12 04:26:06 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0\par
19/10/12 04:26:06 INFO spark.SparkContext: Created broadcast 0 from textFile at JSONRelation.scala:98\par
19/10/12 04:26:06 INFO mapred.FileInputFormat: Total input paths to process : 1\par
19/10/12 04:26:06 INFO spark.SparkContext: Starting job: reduce at JsonRDD.scala:51\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Got job 0 (reduce at JsonRDD.scala:51) with 1 output partitions (allowLocal=false)\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Final stage: Stage 0(reduce at JsonRDD.scala:51)\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Parents of final stage: List()\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Missing parents: List()\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[3] at map at JsonRDD.scala:51), which has no missing parents\par
19/10/12 04:26:06 INFO storage.MemoryStore: ensureFreeSpace(3232) called with curMem=301375, maxMem=280248975\par
19/10/12 04:26:06 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 267.0 MB)\par
19/10/12 04:26:06 INFO storage.MemoryStore: ensureFreeSpace(1898) called with curMem=304607, maxMem=280248975\par
19/10/12 04:26:06 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1898.0 B, free 267.0 MB)\par
19/10/12 04:26:06 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59820 (size: 1898.0 B, free: 267.2 MB)\par
19/10/12 04:26:06 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0\par
19/10/12 04:26:06 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839\par
19/10/12 04:26:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MapPartitionsRDD[3] at map at JsonRDD.scala:51)\par
19/10/12 04:26:06 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\par
19/10/12 04:26:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1332 bytes)\par
19/10/12 04:26:06 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\par
19/10/12 04:26:06 INFO rdd.HadoopRDD: Input split: {{\field{\*\fldinst{HYPERLINK file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327 }}{\fldrslt{file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327\ul0\cf0}}}}\f0\fs22\par
19/10/12 04:26:06 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\par
19/10/12 04:26:06 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\par
19/10/12 04:26:06 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\par
19/10/12 04:26:06 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\par
19/10/12 04:26:06 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\par
19/10/12 04:26:08 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2087 bytes result sent to driver\par
19/10/12 04:26:08 INFO scheduler.DAGScheduler: Stage 0 (reduce at JsonRDD.scala:51) finished in 2.082 s\par
19/10/12 04:26:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2068 ms on localhost (1/1)\par
19/10/12 04:26:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \par
19/10/12 04:26:08 INFO scheduler.DAGScheduler: Job 0 finished: reduce at JsonRDD.scala:51, took 2.244028 s\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing broadcast 1\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing block broadcast_1_piece0\par
19/10/12 04:26:08 INFO storage.MemoryStore: Block broadcast_1_piece0 of size 1898 dropped from memory (free 279944368)\par
19/10/12 04:26:08 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on localhost:59820 in memory (size: 1898.0 B, free: 267.2 MB)\par
19/10/12 04:26:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing block broadcast_1\par
19/10/12 04:26:08 INFO storage.MemoryStore: Block broadcast_1 of size 3232 dropped from memory (free 279947600)\par
19/10/12 04:26:08 INFO spark.ContextCleaner: Cleaned broadcast 1\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing broadcast 0\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing block broadcast_0\par
19/10/12 04:26:08 INFO storage.MemoryStore: Block broadcast_0 of size 280171 dropped from memory (free 280227771)\par
19/10/12 04:26:08 INFO storage.BlockManager: Removing block broadcast_0_piece0\par
19/10/12 04:26:08 INFO storage.MemoryStore: Block broadcast_0_piece0 of size 21204 dropped from memory (free 280248975)\par
19/10/12 04:26:08 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on localhost:59820 in memory (size: 20.7 KB, free: 267.3 MB)\par
19/10/12 04:26:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0\par
19/10/12 04:26:08 INFO spark.ContextCleaner: Cleaned broadcast 0\par
In [7]: twt1.printSchema()\par
root\par
 |-- accountNum: string (nullable = true)\par
 |-- agentName: string (nullable = true)\par
 |-- category: string (nullable = true)\par
 |-- conversationId: string (nullable = true)\par
 |-- messages: array (nullable = true)\par
 |    |-- element: struct (containsNull = true)\par
 |    |    |-- sender: string (nullable = true)\par
 |    |    |-- text: string (nullable = true)\par
 |    |    |-- time: string (nullable = true)\par
In [8]: twt1.show()\par
19/10/12 04:26:38 INFO storage.MemoryStore: ensureFreeSpace(280243) called with curMem=0, maxMem=280248975\par
19/10/12 04:26:38 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 273.7 KB, free 267.0 MB)\par
19/10/12 04:26:38 INFO storage.MemoryStore: ensureFreeSpace(21204) called with curMem=280243, maxMem=280248975\par
19/10/12 04:26:38 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 267.0 MB)\par
19/10/12 04:26:38 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59820 (size: 20.7 KB, free: 267.2 MB)\par
19/10/12 04:26:38 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0\par
19/10/12 04:26:38 INFO spark.SparkContext: Created broadcast 2 from textFile at JSONRelation.scala:98\par
19/10/12 04:26:38 INFO mapred.FileInputFormat: Total input paths to process : 1\par
19/10/12 04:26:38 INFO spark.SparkContext: Starting job: runJob at SparkPlan.scala:121\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Got job 1 (runJob at SparkPlan.scala:121) with 1 output partitions (allowLocal=false)\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Final stage: Stage 1(runJob at SparkPlan.scala:121)\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Parents of final stage: List()\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Missing parents: List()\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at map at SparkPlan.scala:96), which has no missing parents\par
19/10/12 04:26:38 INFO storage.MemoryStore: ensureFreeSpace(4344) called with curMem=301447, maxMem=280248975\par
19/10/12 04:26:38 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 267.0 MB)\par
19/10/12 04:26:38 INFO storage.MemoryStore: ensureFreeSpace(2471) called with curMem=305791, maxMem=280248975\par
19/10/12 04:26:38 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 267.0 MB)\par
19/10/12 04:26:38 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:59820 (size: 2.4 KB, free: 267.2 MB)\par
19/10/12 04:26:38 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0\par
19/10/12 04:26:38 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:839\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[8] at map at SparkPlan.scala:96)\par
19/10/12 04:26:38 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks\par
19/10/12 04:26:38 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1332 bytes)\par
19/10/12 04:26:38 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\par
19/10/12 04:26:38 INFO rdd.HadoopRDD: Input split: {{\field{\*\fldinst{HYPERLINK file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327 }}{\fldrslt{file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327\ul0\cf0}}}}\f0\fs22\par
19/10/12 04:26:38 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 11800 bytes result sent to driver\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Stage 1 (runJob at SparkPlan.scala:121) finished in 0.052 s\par
19/10/12 04:26:38 INFO scheduler.DAGScheduler: Job 1 finished: runJob at SparkPlan.scala:121, took 0.083490 s\par
19/10/12 04:26:38 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on localhost (1/1)\par
19/10/12 04:26:38 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \par
accountNum agentName         category conversationId messages            \par
1          James Hicks       Device   337652         ArrayBuffer([agen...\par
76146      Bradley Meacham   Shipping 337653         ArrayBuffer([agen...\par
88266      Chris Webb        Device   337654         ArrayBuffer([agen...\par
4108       Willis Natal      Device   337655         ArrayBuffer([agen...\par
3714       Beverly Battaglia Shipping 337656         ArrayBuffer([agen...\par
10524      Holly Jackson     Device   337657         ArrayBuffer([agen...\par
31951      Tami Smith        Device   337658         ArrayBuffer([agen...\par
117596     Alvin Lynch       Device   337659         ArrayBuffer([agen...\par
21136      Paul Mastin       Device   337660         ArrayBuffer([agen...\par
75335      Willie Eurich     Device   337661         ArrayBuffer([agen...\par
4137       Rina Harper       Device   337662         ArrayBuffer([agen...\par
22580      Jerome Rucker     Device   337663         ArrayBuffer([agen...\par
15267      Paul Garza        Device   337664         ArrayBuffer([agen...\par
72948      Dennis Russell    Shipping 337665         ArrayBuffer([agen...\par
63327      Charlene Nichols  Device   337666         ArrayBuffer([agen...\par
75370      Kenneth Yonker    Device   337667         ArrayBuffer([agen...\par
118293     Percy Ellis       Device   337668         ArrayBuffer([agen...\par
89590      Mary Chu          Shipping 337669         ArrayBuffer([agen...\par
25198      Mary Ortega       Device   337670         ArrayBuffer([agen...\par
21071      Joann Calhoun     Device   337671         ArrayBuffer([agen...\par
In [9]: twt1.select('agentName').show()\par
19/10/12 04:27:46 INFO storage.MemoryStore: ensureFreeSpace(280243) called with curMem=308262, maxMem=280248975\par
19/10/12 04:27:46 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 273.7 KB, free 266.7 MB)\par
19/10/12 04:27:46 INFO storage.MemoryStore: ensureFreeSpace(21204) called with curMem=588505, maxMem=280248975\par
19/10/12 04:27:46 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KB, free 266.7 MB)\par
19/10/12 04:27:46 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:59820 (size: 20.7 KB, free: 267.2 MB)\par
19/10/12 04:27:46 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0\par
19/10/12 04:27:46 INFO spark.SparkContext: Created broadcast 4 from textFile at JSONRelation.scala:98\par
19/10/12 04:27:46 INFO mapred.FileInputFormat: Total input paths to process : 1\par
19/10/12 04:27:46 INFO spark.SparkContext: Starting job: runJob at SparkPlan.scala:121\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Got job 2 (runJob at SparkPlan.scala:121) with 1 output partitions (allowLocal=false)\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Final stage: Stage 2(runJob at SparkPlan.scala:121)\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Parents of final stage: List()\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Missing parents: List()\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[14] at map at SparkPlan.scala:96), which has no missing parents\par
19/10/12 04:27:46 INFO storage.MemoryStore: ensureFreeSpace(5328) called with curMem=609709, maxMem=280248975\par
19/10/12 04:27:46 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.2 KB, free 266.7 MB)\par
19/10/12 04:27:46 INFO storage.MemoryStore: ensureFreeSpace(2940) called with curMem=615037, maxMem=280248975\par
19/10/12 04:27:46 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 266.7 MB)\par
19/10/12 04:27:46 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:59820 (size: 2.9 KB, free: 267.2 MB)\par
19/10/12 04:27:46 INFO storage.BlockManagerMaster: Updated info of block broadcast_5_piece0\par
19/10/12 04:27:46 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:839\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MapPartitionsRDD[14] at map at SparkPlan.scala:96)\par
19/10/12 04:27:46 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks\par
19/10/12 04:27:46 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1332 bytes)\par
19/10/12 04:27:46 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)\par
19/10/12 04:27:46 INFO rdd.HadoopRDD: Input split: {{\field{\*\fldinst{HYPERLINK file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327 }}{\fldrslt{file:/home/training/training_materials/data/chatlogs/2014-01-01.json:0+2214327\ul0\cf0}}}}\f0\fs22\par
19/10/12 04:27:46 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 2332 bytes result sent to driver\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Stage 2 (runJob at SparkPlan.scala:121) finished in 0.057 s\par
19/10/12 04:27:46 INFO scheduler.DAGScheduler: Job 2 finished: runJob at SparkPlan.scala:121, took 0.072353 s\par
agentName        \par
James Hicks      \par
Bradley Meacham  \par
Chris Webb       \par
Willis Natal     \par
Beverly Battaglia\par
Holly Jackson    \par
Tami Smith       \par
Alvin Lynch      \par
Paul Mastin      \par
Willie Eurich    \par
Rina Harper      \par
Jerome Rucker    \par
Paul Garza       \par
Dennis Russell   \par
Charlene Nichols \par
Kenneth Yonker   \par
Percy Ellis      \par
Mary Chu         \par
Mary Ortega      \par
Joann Calhoun    \par
In [10]: 19/10/12 04:27:46 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 47 ms on localhost (1/1)\par
19/10/12 04:27:46 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool\par
}
 